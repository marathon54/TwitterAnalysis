---
title: "Untitled"
author: "Kevin A. Ryan (JHUAPL)"
date: "Monday, September 28, 2015"
output: html_document
---
Setup
```{r eval=true,warning=FALSE}
library(devtools)
library(httr)
library(rjson)
library(bit64)
library(twitteR)

download.file(url="http://curl.haxx.se/ca/cacert.pem", destfile="cacert.pem")

consumer_key <- 'cD5uXJMuyJfLkodDvYYchEUuM'
consumer_secret <- 'FLVzv3HhHnsSr0qRfnq7ZmCdCWrQS24NUbnREUvHNFhEc89bVg'
access_token <- '740674741-PPuLbrOHGQCYqrh9C9E9AG8I57st4Akj1NBmB2V5'
access_secret <- 'oxsCu5UE9Q6QVowgd98Ds7qFeJIesI9Z3zGk5qDdP3S4m'
setup_twitter_oauth(consumer_key,
                    consumer_secret,
                    access_token,
                    access_secret)

```


```{r}
## Option 1: retrieve tweets from Twitter
library(twitteR)
tweets <- userTimeline("realDonaldTrump", n = 3200)

# convert tweets to a data frame
tweets.df <- twListToDF(tweets)
dim(tweets.df)

for (i in c(1:2, 554)) {
cat(paste0("[", i, "] "))
writeLines(strwrap(tweets.df$text[i], 60))
}

library(tm)
# build a corpus, and specify the source to be character vectors
myCorpus <- Corpus(VectorSource(tweets.df$text))
# convert to lower case
# tm v0.6
myCorpus <- tm_map(myCorpus, content_transformer(tolower))
# tm v0.5-10
# myCorpus <- tm_map(myCorpus, tolower)
# remove URLs
removeURL <- function(x) gsub("http[^[:space:]]*", "", x)
# tm v0.6
myCorpus <- tm_map(myCorpus, content_transformer(removeURL))

# remove anything other than English letters or space
removeNumPunct <- function(x) gsub("[^[:alpha:][:space:]]*", "", x)
myCorpus <- tm_map(myCorpus, content_transformer(removeNumPunct))

#remove punctuation
myCorpus <- tm_map(myCorpus, removePunctuation)

#remove numbers
myCorpus <- tm_map(myCorpus, removeNumbers)

# add two extra stop words: "available" and "via"
myStopwords <- c(stopwords('english'), "realdonaldtrump", "will", "you", "want", "us")

# remove stopwords from corpus
myCorpus <- tm_map(myCorpus, removeWords, myStopwords)
# remove extra whitespace
myCorpus <- tm_map(myCorpus, stripWhitespace)

# keep a copy of corpus to use later as a dictionary for stem completion
myCorpusCopy <- myCorpus
# stem words
myCorpus <- tm_map(myCorpus, stemDocument)
```


```{r}
# tm v0.5-10
# myCorpus <- tm_map(myCorpus, stemCompletion)
# tm v0.6

library(tm)
stemCompletion2 <- function(x, dictionary) f
x <- unlist(strsplit(as.character(x), " "))
# Unexpectedly, stemCompletion completes an empty string to
# a word in dictionary. Remove empty string to avoid above issue.
x <- x[x != ""]
x <- stemCompletion(x, dictionary=dictionary)
x <- paste(x, sep="", collapse=" ")
PlainTextDocument(stripWhitespace(x))
g
myCorpus <- lapply(myCorpus, stemCompletion2, dictionary=myCorpusCopy)
myCorpus <- Corpus(VectorSource(myCorpus))

tdm <- TermDocumentMatrix(myCorpus, control = list(wordLengths = c(1, Inf)))
tdm
```

Frequent Words and Associations
```{r}
(freq.terms <- findFreqTerms(tdm, lowfreq = 25))
term.freq <- rowSums(as.matrix(tdm))
term.freq <- subset(term.freq, term.freq >= 25)
df <- data.frame(term = names(term.freq), freq = term.freq)

library(ggplot2)
ggplot(df, aes(x = term, y = freq)) + geom_bar(stat = "identity") +
xlab("Terms") + ylab("Count") + coord_flip()

# which words are associated with 'XXX'?
findAssocs(tdm, "foxnew", 0.2)
## r
## example 0.33
## code 0.29

#source("http://bioconductor.org/biocLite.R")
#biocLite("Rgraphviz")
par(mar=c(1.5,1.5,1.5,1.5))

library(graph)
library(Rgraphviz)
plot(tdm, term = freq.terms, corThreshold = 0.07, weighting = T, fontsize = 10)


nNodes <- length(freq.terms)
nA <- list()
nA$fixedSize<-rep(FALSE, nNodes)
nA$height <- nA$width <- rep(".2", nNodes)
nA$label <- freq.terms
nA$color <- rep("green", nNodes)
nA$fillcolor <- rep("orange", nNodes)
nA$shape <- rep("circle", nNodes)
nA$fontcolor <- rep("blue", nNodes)
nA$fontsize <- rep(20, nNodes)
nA <- lapply(nA, function(x) { names(x) <- freq.terms; x})
plot(tdm, term = freq.terms, nodeAttrs=nA, corThreshold = 0.15, weighting = T)


```
